%
% File proposal_template.tex
%
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2019}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{Grammar Feedback for Non-Native Hindi Learners}

\author{Uddip Yalamanchili \\
  Dept. of Computer Science\\
  George Mason University \\
  \texttt{uyalaman@gmu.edu} \\\And
  Aditya Shah \\
  Dept. of Computer Science\\
  George Mason University \\
  \texttt{ashah49@gmu.edu} \\\And
  Nikhil Chukka\\
  Dept. of Computer Science\\
  George Mason University \\
  \texttt{nchukka@gmu.edu} \\}
\date{}

\begin{document}
\maketitle

\section{Introduction}

\subsection{Task / Research Question Description}

The task is to develop a tool that provides 
% personalized 
grammar feedback for non-native Hindi learners. The goal is to help learners identify 
% and correct 
their grammatical errors, facilitating their journey toward fluency.

\subsection{ Motivation and Limitations of existing work}

Existing resources primarily focus on vocabulary and basic phrases, but they lack personalized grammar feedback. While others have addressed general Hindi language learning, this project aims to offer real-time, individualized feedback that enhances learners' understanding of grammar, which existing solutions do not sufficiently provide. Prior efforts have not been able to cater to personalized grammar refinement, especially for self-directed learners.

\subsection{Proposed Approach}

% Briefly describe some of your initial thoughts about your proposed approach and your preliminary ideas 
The proposed approach\textit{(tentative approaches)} includes integrating rule-based and pre-trained NLP models to detect grammatical errors and provide suggestions. Initial ideas involve using existing public datasets, pre-trained models %from platforms like Hugging Face, 
and machine translation tools. The development of an API that allows users to input sentences and receive corrections and explanations is also planned.

\subsection{Likely challenges and mitigations}
% What is hard about this task / research question? What are your contingency plans if things turn out to be harder than expected or experiments do not go as planned? 
Challenges include accurately detecting complex grammatical errors, handling diverse sentence structures, and ensuring the tool's performance. To mitigate these, the project plans to use a combination of rule-based systems and machine-learning models. Additionally, there are contingency plans to involve human evaluations and real-world user testing to refine and improve the accuracy of the feedback tool.
\\
%{should also talk about the challenges about the dataset and also the efforts require to evaluate the performance of the tool.}
\section{Related Work}
\subsection{Vyakranly: Hindi Grammar \& Spelling Errors Detection and Correction System:} 
% Vyakranly focuses on addressing the growing need for automated Hindi language tools by providing a system that detects and corrects both spelling and grammar errors. It employs a combination of rule-based and statistical approaches, utilizing morphological analysis and part-of-speech tagging. The system is primarily designed for simple sentences but can also handle some compound sentences. Vyakranly integrates modules for grammar checking, spell correction, and translation between Hindi and English, aiming to create a holistic language processing tool for Hindi learners.

% The existing grammar correction systems mainly address errors like adjective-noun and noun-verb agreements for simple sentences, as seen in prior works. However, they often lack the capacity to handle complex sentence structures, which Vyakranly attempts to overcome by employing hybrid methods that combine statistical techniques with rule-based corrections. Additionally, while many spell-checking tools are available, they often do not integrate grammar correction, making Vyakranly distinct in its combined approach.
Vyakranly is an automated tool for Hindi that detects and corrects both spelling and grammar errors using a combination of rule-based and statistical methods, including morphological analysis and part-of-speech tagging. It is designed for simple sentences but can handle some compound structures, distinguishing itself by integrating grammar checking, spell correction, and translation between Hindi and English (no actual implementation). However, the model struggles with complex sentence patterns and may produce less accurate results when dealing with intricate grammatical structures or idiomatic expressions.\cite{s_vyakranly_2023}

\subsection{Detection and Correction of Grammatical Errors in Hindi Language Using Hybrid Approach:} 
% This research developed a grammar checking system for Hindi using a hybrid approach that combines statistical and rule-based methods. The system addresses four types of grammatical errors, including adjective-noun and noun-verb agreement errors in terms of number and gender. By using a combination of morphological analysis, part-of-speech tagging, and pattern-based bigram and trigram methods, it effectively identifies and corrects grammatical issues in simple Hindi sentences. The system achieved a precision of 0.83, recall of 0.91, and an F-measure of 0.87. However, the approach mainly focuses on simple sentences, and its application to more complex structures remains limited. 

This article describes a Hindi grammar-checking system created with a hybrid approach that incorporates statistical and rule-based approaches. The approach efficiently corrects four common grammatical problems, including number and gender-related adjective-noun and noun-verb agreement difficulties. It uses a combination of morphological analysis, part-of-speech tagging, and pattern-based bigram and trigram models to detect and fix problems in short Hindi phrases. The system produced strong performance measures, including an accuracy of 0.83, recall of 0.91, and F-measure of 0.87. However, its architecture is largely focused on basic sentence constructions, restricting its ability to handle more complex grammatical types. \cite{mittal_detection_2019}

\subsection{Frequency-based Spell Checking and
Rule-based Grammar Checking :}
 In this paper, authors developed a hybrid system combining frequency-based spell checking with rule-based grammar checking, focusing on implementing comprehensive tense rules using JSON for rule representation and demonstrating effective encoding of grammatical rules through POS tagging and parsing.
 \cite{singh2016frequency}

 \subsection{Bangla Grammatical Error Detection Using T5
 Transformer Model:}
 The Bangla Grammatical Error Detection paper (2023) 
 showcased the application of T5 Transformer (60M parameters) 
 fine-tuned on 9,385 sentences with error symbols, achieving a Levenshtein Distance of 1.0394 through extensive post-processing and specialized correction mechanisms for morphologically rich language features. \cite{shahgir2023bangla}\\

Our work differs by implementing a multi-model architecture specifically for Hindi that combines neural models with linguistic rules, moving beyond the purely rule-based approach of Singh et al. and the single-model architecture of the Bangla work, while incorporating Hindi-specific linguistic features and error patterns.
% \section{Methodology}

% This section must explain your approach to solving the problem. Remember, that this should ensure that your work is potentially reproducible, so try to be as detailed as possible. You don't need to describe established models/architectures from previous work as long as you appropriately cite the relevant papers. If you use prompt-based techniques, make sure to include your prompts (e.g. in an Appendix) along with the generation configuration.
\section{Methodology}

%\subsection{Approach to Solving the Problem}

To develop a tool that provides personalized grammar feedback for non-native Hindi learners, we propose a hybrid approach that combines the power of transformer-based language models with rule-based grammar correction mechanisms. Our solution is designed to provide real-time and personalized feedback to facilitate the learners' journey toward fluency in Hindi. The approach is as follows, data preparation, model selection and training, error detection, error correction, and personalization.

\textbf{Data Preparation}: We planned to create a high-quality dataset of 20,000 Hindi sentences, both correct and incorrect, simulating common errors made by non-native speakers. This helps the model effectively learn error patterns for accurate corrections.

\textbf{Model Selection and Training}: Planning to fine-tune a small HindiT5 model (60M parameters)
%This Hindi T5 model does not exist
for grammatical error detection. The model was trained for 100 epochs using 80\% of the data, optimizing with AdamW.

\textbf{Error Detection}: The model uses an encoder-decoder structure to identify and correct common grammatical errors. It detects issues like incorrect gender or number agreement and verb conjugations.
% on the above line it says that it uses t5 model and here it talks about encoder and decoder structure - which is not in line

\textbf{Post-Processing and Error Correction}: Post-processing involves character-level corrections, dictionary lookups, and regular expressions to refine the output. This ensures grammatical correctness while retaining sentence meaning.

% \textbf{Personalized Feedback System}: A personalization layer tracks user errors to provide targeted suggestions. This helps users address recurring mistakes effectively, enhancing learning outcomes.

\textbf{Evaluation Metrics}: We evaluate the model using Levenshtein Distance, Precision, Recall, and F1 score. 
% The model achieved strong performance, indicating effective error identification and correction.

\textbf{Reproducibility}: We document the dataset, model architecture, and hyperparameters to ensure reproducibility. Regular expression rules and model scripts will also be provided for further research.

\textbf{Evaluation}: We plan for both automated and human evaluation for comprehensive analysis. This approach ensures the model's effectiveness across various user proficiencies.

% \textbf{Unit Testing}: Each component underwent unit testing, such as tokenization and error detection, to verify functionality. This ensures the stability and correctness of system modules before integration.

\textbf{Automated Evaluation}: We used metrics like Levenshtein Distance and F1 score to objectively assess corrections. This provides consistency in performance evaluation across grammatical error types.

\textbf{Human Evaluation}: 
% Native and non-native Hindi speakers evaluated fluency, adequacy, and feedback utility.
The human evaluation addresses nuances that automated metrics might miss.

\textbf{Hybrid Approach}: A hybrid of automated metrics and human evaluation will be used to balance efficiency and qualitative insights. This ensures a comprehensive understanding of model performance.

% \subsection{Evaluation} 
% How will you evaluate your system? Will you write unit tests? Will you perform human evaluation, or will you use automatic references, and why?

\section{Experiments}

\subsection{Datasets}
Please list which datasets you plan to use , whether or not you have access them, and whether or not they are publicly available with the same preprocessing and train / dev / tests as the previous work you will be comparing to (if applicable). If you plan to collect your own dataset, please describe clearly the data plan (the data source, how you plan to collect it, how you would preprocess it for the task, etc.).

\subsection{Implementation} 
Please provide a link to a repo of your implementation (if applicable) and appropriately cite any resources you have used.

\subsection{Results}
Provide a table with your results.

\subsection{Discussion}
Analyze the performance of your model. Discuss any issues you faced. Did you do a sensitivity analysis (e.g. multiple runs with different random seeds)?

\subsection{Resources}
Discuss the cost of your solution in terms of resources: computation, time, people, development effort.


\subsection{Error Analysis}
Perform an error analysis on the system. Include at least 2-3 instances where your system fails and 2-3 where it succeeds.


\section{Conclusion}
Summarize your contribution in three sentences.

% \section{Credits}

% This document has been adapted from the instructions
% for earlier ACL and NAACL proceedings,
% including 
% those for 
% NAACL 2019 by Stephanie Lukin and Alla Roskovskaya, 
% ACL 2018 by Shay Cohen, Kevin Gimpel, and Wei Lu, 
% NAACL 2018 by Margaret Michell and Stephanie Lukin,
% 2017/2018 (NA)ACL bibtex suggestions from Jason Eisner,
% ACL 2017 by Dan Gildea and Min-Yen Kan, 
% NAACL 2017 by Margaret Mitchell, 
% ACL 2012 by Maggie Li and Michael White, 
% those from ACL 2010 by Jing-Shing Chang and Philipp Koehn, 
% those for ACL 2008 by JohannaD. Moore, Simone Teufel, James Allan, and Sadaoki Furui, 
% those for ACL 2005 by Hwee Tou Ng and Kemal Oflazer, 
% those for ACL 2002 by Eugene Charniak and Dekang Lin, 
% and earlier ACL and EACL formats.
% Those versions were written by several
% people, including John Chen, Henry S. Thompson and Donald
% Walker. Additional elements were taken from the formatting
% instructions of the \emph{International Joint Conference on Artificial
%   Intelligence} and the \emph{Conference on Computer Vision and
%   Pattern Recognition}.

\bibliographystyle{acl_natbib} % We choose the "plain" reference style
\bibliography{refs} % Entries are in the refs.bib file

\end{document}
